import json
import os
import re
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_groq import ChatGroq
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from app.core.config import settings
from app.graph2.state import AgentState

llm = ChatGroq(
    model_name="llama-3.1-8b-instant", 
    groq_api_key=settings.GROQ_API_KEY,
    temperature=0.4
)

# ============== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ==============

def extract_json(text: str):
    """ë¬¸ìì—´ì—ì„œ JSON ë¸”ë¡ì„ ì¶”ì¶œí•˜ì—¬ íŒŒì‹±í•©ë‹ˆë‹¤."""
    text = text.strip()
    if "```json" in text:
        text = text.split("```json")[1].split("```")[0].strip()
    elif "```" in text:
        text = text.split("```")[1].split("```")[0].strip()
    
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        # JSON ì „í›„ì— í…ìŠ¤íŠ¸ê°€ ì„ì—¬ ìˆì„ ê²½ìš° { } ë¥¼ ì°¾ì•„ ì‹œë„
        start = text.find('{')
        end = text.rfind('}')
        if start != -1 and end != -1:
            try:
                return json.loads(text[start:end+1])
            except:
                pass
        # ë°°ì—´ í˜•íƒœ [ ] ë„ ì‹œë„
        start = text.find('[')
        end = text.rfind(']')
        if start != -1 and end != -1:
            try:
                return json.loads(text[start:end+1])
            except:
                pass
        raise

# ============== ë…¸ë“œ í•¨ìˆ˜ë“¤ ==============

def intent_classifier_node(state: AgentState) -> AgentState:
    """ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë¶„ë¥˜í•˜ëŠ” ë…¸ë“œ"""
    print("\n=== ì˜ë„ ë¶„ë¥˜ ì¤‘ ===")
    
    messages = state.get("messages", [])
    if not messages:
        return AgentState(intent="general_chat", current_step="intent_classifier")
    
    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì°¾ê¸°
    user_input = ""
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            user_input = msg.content
            break
    
    if not user_input:
        return AgentState(intent="general_chat", current_step="intent_classifier")
        
    # í˜„ì¬ ìˆ˜ì§‘ëœ ì •ë³´ ìƒíƒœ í™•ì¸ (ì˜ë„ ë¶„ë¥˜ì— ì°¸ê³ )
    current_prefs = state.get("user_preferences", {})
    progress = f" (í˜„ì¬ ìˆ˜ì§‘ëœ ì •ë³´: {list(current_prefs.keys())})" if current_prefs else ""

    system_prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì…ë ¥ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë¶„ë¥˜ê¸°ì…ë‹ˆë‹¤.
    ë‹¤ìŒ ì„¸ ê°€ì§€ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:
    1. "recommend_travel": ì—¬í–‰ì§€ì™€ ê´€ë ¨ëœ ì§ˆë¬¸, ì¶”ì²œ ìš”ì²­, ì—¬í–‰ ê³„íš(ì˜ˆì‚°, ê¸°ê°„, ì¥ì†Œ ë“±) ë‹µë³€, ì—¬í–‰ ê´€ë ¨ ì¶”ê°€ ìš”êµ¬ì‚¬í•­ ë“±{progress}
    2. "general_chat": ì¸ì‚¬(ì•ˆë…•í•˜ì„¸ìš”, ë°˜ê°€ì›Œìš”), ì‹œìŠ¤í…œ ê´€ë ¨ ì§ˆë¬¸(ë„Œ ëˆ„êµ¬ë‹ˆ?), ì¹­ì°¬, ê°„ë‹¨í•œ ì¼ìƒ ëŒ€í™” ë“±
    3. "irrelevant_chat": ì—¬í–‰ê³¼ ì „í˜€ ìƒê´€ì—†ëŠ” ì£¼ì œ(ì •ì¹˜, ê¸°ìˆ  ì§ˆë¬¸, ìš”ë¦¬ ë ˆì‹œí”¼ ë“±)ë‚˜ ë¶€ì ì ˆí•œ ì–¸ì–´

    ì‚¬ìš©ìê°€ ì—¬í–‰ ì¡°ê±´ì„ ë§í•˜ê³  ìˆë‹¤ë©´ ë°˜ë“œì‹œ "recommend_travel"ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
    ì‘ë‹µì€ ì˜¤ì§ í•œ ë‹¨ì–´(recommend_travel, general_chat, irrelevant_chat)ë¡œë§Œ í•˜ì„¸ìš”."""
    
    # ìµœê·¼ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬í•¨ (ìµœê·¼ 10ê°œë¡œ í™•ëŒ€)
    recent_messages = messages[-10:] if len(messages) > 10 else messages
    chat_messages = [SystemMessage(content=system_prompt)] + recent_messages
    
    response = llm.invoke(chat_messages)
    
    intent = response.content.strip().lower()
    # ì—„ê²©í•œ í•„í„°ë§: ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ ëŒ€ë¹„
    if "recommend" in intent:
        intent = "recommend_travel"
    elif "general" in intent:
        intent = "general_chat"
    elif "irrelevant" in intent:
        intent = "irrelevant_chat"
    # ë§Œì•½ ê¸°ì¡´ì— ì •ë³´ê°€ ìˆ˜ì§‘ ì¤‘ì´ì—ˆë‹¤ë©´ ê¸°ë³¸ê°’ì„ ì—¬í–‰ ì¶”ì²œìœ¼ë¡œ ë” ê°•ë ¥í•˜ê²Œ ì„¤ì •
    elif current_prefs and len(current_prefs) > 0:
        intent = "recommend_travel"
    else:
        intent = "recommend_travel" # ê¸°ë³¸ê°’
        
    print(f"ë¶„ë¥˜ëœ ì˜ë„: {intent}")
    return AgentState(intent=intent, current_step="intent_classifier")


def general_chat_node(state: AgentState) -> AgentState:
    """ê°„ë‹¨í•œ ì¸ì‚¬ë‚˜ ì¼ìƒ ëŒ€í™”ì— ì‘ë‹µí•˜ëŠ” ë…¸ë“œ"""
    print("\n=== ì¼ìƒ ëŒ€í™” ì‘ë‹µ ì¤‘ ===")
    
    messages = state.get("messages", [])
        
    system_prompt = """ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì—¬í–‰ ì „ë¬¸ê°€ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
    ì‚¬ìš©ìì˜ ì¸ì‚¬ë‚˜ ê°€ë²¼ìš´ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì§§ê²Œ ëŒ€ë‹µí•˜ì„¸ìš”. 
    ê·¸ë¦¬ê³  ìì—°ìŠ¤ëŸ½ê²Œ êµ­ë‚´ ì—¬í–‰ì§€ ì¶”ì²œì´ í•„ìš”í•˜ë©´ ì–¸ì œë“  ë§ì”€í•´ë‹¬ë¼ê³  ë§ë¶™ì´ì„¸ìš”.
    ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ë”°ëœ»í•œ ë¶„ìœ„ê¸°ë¥¼ ë§Œë“œì„¸ìš”.
    
    ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•˜ì„¸ìš”."""
    
    # ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨ (ìµœê·¼ 10ê°œ)
    recent_messages = messages[-10:] if len(messages) > 10 else messages
    chat_messages = [SystemMessage(content=system_prompt)] + recent_messages
    
    response = llm.invoke(chat_messages)
    
    # ê¸°ì¡´ ë©”ì‹œì§€ì— AI ì‘ë‹µ ì¶”ê°€ (ë¦¬ë“€ì„œê°€ ìˆìœ¼ë¯€ë¡œ ìƒˆë¡œìš´ ë©”ì‹œì§€ë§Œ ë°˜í™˜)
    return AgentState(
        messages=[AIMessage(content=response.content)],
        current_step="general_chat"
    )


def irrelevant_chat_node(state: AgentState) -> AgentState:
    """ì£¼ì œì—ì„œ ë²—ì–´ë‚œ ì§ˆë¬¸ì— ëŒ€í•´ ê°€ì´ë“œë¥¼ ì£¼ëŠ” ë…¸ë“œ"""
    print("\n=== ë¶€ì í•© ëŒ€í™” ì•ˆë‚´ ì¤‘ ===")
    
    messages = state.get("messages", [])
    
    system_prompt = """ë‹¹ì‹ ì€ 'ëŒ€í•œë¯¼êµ­ êµ­ë‚´ ì—¬í–‰ ì „ë¬¸ê°€'ì…ë‹ˆë‹¤. 
    ì‚¬ìš©ìê°€ ì—¬í–‰ê³¼ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì„ í•˜ê±°ë‚˜ ë¶€ì ì ˆí•œ ë§ì„ í–ˆì„ ë•Œ, 
    ì •ì¤‘í•˜ê²Œ ë‹¹ì‹ ì˜ ì—­í• ì„ ì„¤ëª…í•˜ê³  ì—¬í–‰ì— ê´€í•œ ì§ˆë¬¸ë§Œ í•´ë‹¬ë¼ê³  ì•ˆë‚´í•˜ì„¸ìš”.
    ë‹¨í˜¸í•˜ì§€ë§Œ ì¹œì ˆí•œ ë§íˆ¬ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
    
    ì´ì „ ëŒ€í™”ê°€ ìˆë‹¤ë©´ ì°¸ê³ í•˜ì—¬ ë§¥ë½ì— ë§ê²Œ ì‘ë‹µí•˜ì„¸ìš”."""
    
    # ìµœê·¼ ëŒ€í™” í¬í•¨
    recent_messages = messages[-5:] if len(messages) > 5 else messages
    chat_messages = [SystemMessage(content=system_prompt)] + recent_messages
    
    response = llm.invoke(chat_messages)
    
    return AgentState(
        messages=[AIMessage(content=response.content)],
        current_step="irrelevant_chat"
    )


def collect_preferences_node(state: AgentState) -> AgentState:
    """ì‚¬ìš©ì ì„ í˜¸ë„ ìˆ˜ì§‘ ë…¸ë“œ"""
    print("\n=== ì…ë ¥ ìˆ˜ì§‘ ì¤‘ ===")
    
    messages = state.get("messages", [])
    current_prefs = state.get("user_preferences", {})
    
    # ì´ˆê¸° ë©”ì‹œì§€ëŠ” service.pyì—ì„œ ì´ë¯¸ HumanMessageê°€ ë“¤ì–´ì˜¤ë¯€ë¡œ 
    # messagesê°€ ì•„ì˜ˆ ë¹„ì–´ìˆëŠ” ê²½ìš°ëŠ” ë“œë¬¼ì§€ë§Œ, ì•ˆì „ì„ ìœ„í•´ ì²˜ë¦¬
    if not messages:
        return AgentState(
            user_preferences={},
            messages=[AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”! ì™„ë²½í•œ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì˜ˆì‚°, ì—¬í–‰ ê¸°ê°„, ê´€ì‹¬ì‚¬ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.")],
            current_step="collect_preferences"
        )
    
    # graph.pyì™€ ë™ì¼í•˜ê²Œ duration ì¶”ê°€
    required_fields = ["budget", "duration", "interests"]
    has_all = all(field in current_prefs and current_prefs[field] for field in required_fields)
    
    # has_all ì—¬ë¶€ì™€ ìƒê´€ì—†ì´ í•­ìƒ ìµœì‹  ë©”ì‹œì§€ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œ/ì—…ë°ì´íŠ¸ ì‹œë„
    # (ì‚¬ìš©ìê°€ ì¤‘ê°„ì— ë§ˆìŒì„ ë°”ê¿¨ê±°ë‚˜ ëˆ„ë½ëœ ì •ë³´ë¥¼ ì±„ìš°ëŠ” ê²½ìš° ëŒ€ì‘)
    system_prompt = """ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ êµ­ë‚´ ì—¬í–‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    **ì „ì²´ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•´ì„œ** ì‚¬ìš©ìì˜ ì—¬í–‰ ì„ í˜¸ë„ë¥¼ íŒŒì•…í•´ì£¼ì„¸ìš”.
    
    í•„ìš”í•œ ì •ë³´:
    - budget (ì˜ˆì‚°: ì˜ˆ) 50ë§Œì›, 100ë§Œì› ë“±)
    - duration (ì—¬í–‰ ê¸°ê°„: ì˜ˆ) 2ë°• 3ì¼, 3ì¼ ë“±)
    - interests (ê´€ì‹¬ì‚¬: ë¬¸í™”, ìì—°, ìŒì‹, ì•¡í‹°ë¹„í‹° ë“±)
    - travel_style (ì—¬í–‰ ìŠ¤íƒ€ì¼: íœ´ì–‘, ëª¨í—˜, ê´€ê´‘ ë“±)
    - season (ì„ í˜¸ ê³„ì ˆ ë˜ëŠ” ì—¬í–‰ ì‹œê¸°)
    - companion (ë™í–‰ì¸: í˜¼ì, ê°€ì¡±, ì—°ì¸, ì¹œêµ¬ ë“±)
    
    ê¸°ì¡´ì— ìˆ˜ì§‘ëœ ì •ë³´ê°€ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ê¸°ë°˜ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ê³ , 
    ë¶€ì¡±í•œ ì •ë³´ëŠ” 'missing_fields'ì— ë‚˜ì—´í•˜ì„¸ìš”.
    íŠ¹íˆ budget, duration, interestsëŠ” ì¶”ì²œì„ ì‹œì‘í•˜ê¸° ìœ„í•œ í•„ìˆ˜ ì •ë³´ì…ë‹ˆë‹¤.
    
    JSON í˜•íƒœë¡œë§Œ ì‘ë‹µ:
    {{
        "budget": "...",
        "duration": "...",
        "interests": "...",
        "travel_style": "...",
        "season": "...",
        "companion": "...",
        "missing_fields": ["field1", "field2"]
    }}
    
    ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ì˜¤ì§ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”."""
    
    try:
        # ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬ + ê¸°ì¡´ ìˆ˜ì§‘ ì •ë³´ ì „ë‹¬
        chat_messages = [SystemMessage(content=system_prompt)]
        
        # ê¸°ì¡´ ìˆ˜ì§‘ ì •ë³´ë¥¼ ì‹œìŠ¤í…œ ë©”ì‹œì§€ì— í¬í•¨
        if current_prefs:
            chat_messages.append(SystemMessage(content=f"ê¸°ì¡´ì— ìˆ˜ì§‘ëœ ì •ë³´: {json.dumps(current_prefs, ensure_ascii=False)}"))
        
        # ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
        chat_messages.extend(messages)
        
        response = llm.invoke(chat_messages)
        result = extract_json(response.content)
        
        # ì •ë³´ ë³‘í•© (ê°’ì´ ìˆëŠ” ê²ƒë§Œ ì—…ë°ì´íŠ¸)
        new_preferences = {**current_prefs}
        for k, v in result.items():
            if k != "missing_fields" and v and v != "..." and v != "None" and "ì•Œ ìˆ˜" not in str(v):
                new_preferences[k] = v
        
        # í•„ìˆ˜ ì •ë³´ í™•ì¸
        final_missing = [f for f in required_fields if f not in new_preferences or not new_preferences[f]]
        
        if final_missing:
            # ì•„ì§ ë¶€ì¡±í•œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
            # ë§Œì•½ ë°©ê¸ˆ ì •ë³´ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆë‹¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ìŒ ì§ˆë¬¸
            response_text = f"ì•Œê² ìŠµë‹ˆë‹¤! {', '.join(final_missing)} ì •ë³´ë„ ì•Œë ¤ì£¼ì‹œë©´ ìµœì ì˜ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œí•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            
            return AgentState(
                user_preferences=new_preferences,
                messages=[AIMessage(content=response_text)],
                current_step="collect_preferences"
            )
        
        # ëª¨ë“  í•„ìˆ˜ ì •ë³´ ì™„ë£Œ
        quality = sum(1 for f in required_fields if f in new_preferences) / len(required_fields)
        
        # ì´ë¯¸ ì™„ë£Œ ë©”ì‹œì§€ê°€ ë‚˜ê°„ ì ì´ ìˆëŠ”ì§€ í™•ì¸ (ì¤‘ë³µ ë©”ì‹œì§€ ë°©ì§€)
        # matches = [m for m in messages if "ëª¨ë“  ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ" in getattr(m, 'content', '')]
        # if matches and has_all: # ì´ë¯¸ ë‹¤ ëª¨ì•˜ëŠ”ë° ë˜ ë“¤ì–´ì˜¨ ê²½ìš°ë©´ ë©”ì‹œì§€ ìƒëµ ê°€ëŠ¥
        #     return AgentState(user_preferences=new_preferences, current_step="collect_preferences")

        return AgentState(
            user_preferences=new_preferences,
            info_quality_score=quality,
            messages=[AIMessage(content="ëª¨ë“  ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ! ë§ì¶¤ ì—¬í–‰ì§€ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤...")],
            current_step="collect_preferences"
        )
        
    except Exception as e:
        print(f"íŒŒì‹± ì˜¤ë¥˜: {e}")
        return AgentState(
            messages=[AIMessage(content="ì •ë³´ë¥¼ ì´í•´í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì˜ˆì‚°, ê¸°ê°„, ê´€ì‹¬ì‚¬ë¥¼ ë‹¤ì‹œ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?")],
            current_step="collect_preferences"
        )



def generate_candidates_node(state: AgentState) -> AgentState:
    """ì—¬í–‰ì§€ í›„ë³´ ìƒì„± ë…¸ë“œ"""
    print("\n=== í›„ë³´ì§€ ìƒì„± ì¤‘ ===")
    
    prefs = state["user_preferences"]
    retry_count = state.get("retry_count", 0)
    messages = state.get("messages", [])
    
    # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì‚¬ìš©ìì˜ ì¶”ê°€ ìš”êµ¬ì‚¬í•­ íŒŒì•…
    conversation_context = "\n".join([
        msg.content for msg in messages[-5:] 
        if isinstance(msg, (HumanMessage, AIMessage))
    ])
    
    system_prompt = f"""ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ êµ¬ì„êµ¬ì„ì„ ê¿°ëš«ê³  ìˆëŠ” êµ­ë‚´ ì—¬í–‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì‚¬ìš©ìì˜ ì„ í˜¸ë„ì™€ ëŒ€í™” ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì ì˜ **êµ­ë‚´ ì—¬í–‰ì§€(í•œêµ­ ë‚´ ë„ì‹œ ë° ì§€ì—­)** 3-5ê°œë¥¼ ì¶”ì²œí•˜ì„¸ìš”.

    ì‚¬ìš©ì ì •ë³´:
    {json.dumps(prefs, ensure_ascii=False, indent=2)}
    
    ìµœê·¼ ëŒ€í™” ë‚´ìš©:
    {conversation_context}

    {"[ì£¼ì˜] ì´ì „ ì¶”ì²œì´ ì„ í˜¸ë„ì™€ ë§ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì§€ì—­ì´ë‚˜ ë‹¤ë¥¸ í…Œë§ˆì˜ í•œêµ­ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”." if retry_count > 0 else ""}

    ê° ì—¬í–‰ì§€ì— ëŒ€í•´ ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”:
    - destination: ì—¬í–‰ì§€ ì´ë¦„ (ì˜ˆ: ì œì£¼ë„, ê²½ì£¼, ì–‘ì–‘ ë“±)
    - country: "ëŒ€í•œë¯¼êµ­"
    - province: ë„ ë‹¨ìœ„
    - reason: ì¶”ì²œ ì´ìœ  (ëŒ€í™” ë‚´ìš©ê³¼ ì—°ê²°)
    - estimated_cost: ì˜ˆìƒ ë¹„ìš© (ì›)
    - best_season: ìµœì  ë°©ë¬¸ ì‹œê¸°
    - highlights: ì£¼ìš” ë³¼ê±°ë¦¬ 3ê°€ì§€

    ì‘ë‹µì€ ë°˜ë“œì‹œ JSON ë°°ì—´ í˜•íƒœë¡œë§Œ í•˜ì„¸ìš”."""
    
    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content="ì—¬í–‰ì§€ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.")
    ])
    
    try:
        candidates = extract_json(response.content)
        print(f"ìƒì„±ëœ í›„ë³´: {len(candidates)}ê°œ")
        
        return AgentState(
            candidates=candidates,
            messages=[AIMessage(content=f"{len(candidates)}ê°œì˜ ì—¬í–‰ì§€ í›„ë³´ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")],
            current_step="generate_candidates"
        )
    except Exception as e:
        print(f"í›„ë³´ ìƒì„± ì˜¤ë¥˜: {e}")
        return AgentState(
            candidates=[],
            validation_score=0.0,
            validation_feedback="í›„ë³´ ìƒì„± ì‹¤íŒ¨",
            messages=[AIMessage(content="í›„ë³´ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")],
            current_step="generate_candidates"
        )


def validate_candidates_node(state: AgentState) -> AgentState:
    """í›„ë³´ì§€ í’ˆì§ˆ ê²€ì¦ ë…¸ë“œ"""
    print("\n=== í›„ë³´ ê²€ì¦ ì¤‘ ===")
    
    candidates = state["candidates"]
    prefs = state["user_preferences"]
    messages = state.get("messages", [])
    
    if not candidates:
        return AgentState(
            validation_score=0.0,
            validation_feedback="í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤",
            messages=[AIMessage(content="ê²€ì¦í•  í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")],
            current_step="validate_candidates"
        )
    
    system_prompt = f"""í›„ë³´ ì—¬í–‰ì§€ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ì„¸ìš”.
    
    ì‚¬ìš©ì ì„ í˜¸ë„:
    {json.dumps(prefs, ensure_ascii=False, indent=2)}
    
    í›„ë³´ ëª©ë¡:
    {json.dumps(candidates, ensure_ascii=False, indent=2)}
    
    í‰ê°€ ê¸°ì¤€:
    1. ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ì¼ì¹˜ë„ - 40ì 
    2. í›„ë³´ ë‹¤ì–‘ì„± - 30ì 
    3. ì‹¤í˜„ ê°€ëŠ¥ì„± - 20ì 
    4. ì •ë³´ êµ¬ì²´ì„± - 10ì 
    
    JSONìœ¼ë¡œë§Œ ì‘ë‹µ:
    {{
        "score": 0.0-1.0,
        "feedback": "í‰ê°€ ì„¤ëª…",
        "issues": ["ë¬¸ì œì "]
    }}"""
    
    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content="í›„ë³´ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.")
    ])
    
    try:
        content = response.content.strip()
        if content.startswith("```json"):
            content = content[7:]
        if content.startswith("```"):
            content = content[3:]
        if content.endswith("```"):
            content = content[:-3]
            
        validation = json.loads(content.strip())
        score = float(validation.get("score", 0.0))
        feedback = validation.get("feedback", "")
        
        print(f"ê²€ì¦ ì ìˆ˜: {score:.2f}")
        
        return AgentState(
            validation_score=score,
            validation_feedback=feedback,
            messages=[AIMessage(content=f"í›„ë³´ ê²€ì¦ ì™„ë£Œ (ì ìˆ˜: {score:.2f})")],
            current_step="validate_candidates"
        )
    except Exception as e:
        print(f"ê²€ì¦ ì˜¤ë¥˜: {e}")
        return AgentState(
            validation_score=0.5,
            validation_feedback="ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
            messages=[AIMessage(content="ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")],
            current_step="validate_candidates"
        )

def enrich_information_node(state: AgentState) -> AgentState:
    """ì—¬í–‰ì§€ ì •ë³´ ë³´ê°• ë…¸ë“œ"""
    print("\n=== ì •ë³´ ìˆ˜ì§‘ ì¤‘ ===")
    
    candidates = state["candidates"]
    messages = state.get("messages", [])
    
    system_prompt = """ê° ì—¬í–‰ì§€ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”:
    - weather: í˜„ì¬ ê³„ì ˆì˜ ë‚ ì”¨/ê¸°í›„
    - safety: ì•ˆì „ ì •ë³´
    - transport: êµí†µ ì •ë³´
    - tips: ì—¬í–‰ íŒ
    - recent_reviews: ìµœê·¼ í”¼ë“œë°±
    
    enriched_info í•„ë“œë¥¼ ì¶”ê°€í•œ JSON ë°°ì—´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
    ì›ë³¸ ì •ë³´ëŠ” ìœ ì§€í•˜ê³  enriched_infoë§Œ ì¶”ê°€í•˜ì„¸ìš”."""
    
    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ë‹¤ìŒ ì—¬í–‰ì§€ë“¤ì˜ ì •ë³´ë¥¼ ë³´ê°•í•˜ì„¸ìš”:\n{json.dumps(candidates, ensure_ascii=False, indent=2)}")
    ])
    
    try:
        enriched = extract_json(response.content)
        print(f"ì •ë³´ ë³´ê°• ì™„ë£Œ: {len(enriched)}ê°œ")
        
        return AgentState(
            enriched_data=enriched,
            messages=[AIMessage(content="ì—¬í–‰ì§€ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤.")],
            current_step="enrich_information"
        )
    except Exception as e:
        print(f"ì •ë³´ ë³´ê°• ì˜¤ë¥˜: {e}")
        return AgentState(
            enriched_data=candidates,
            messages=[AIMessage(content="ì •ë³´ ë³´ê°•ì„ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤.")],
            current_step="enrich_information"
        )


def validate_information_node(state: AgentState) -> AgentState:
    """ìˆ˜ì§‘ëœ ì •ë³´ì˜ í’ˆì§ˆ ê²€ì¦ ë…¸ë“œ"""
    print("\n=== ì •ë³´ í’ˆì§ˆ ê²€ì¦ ì¤‘ ===")
    
    enriched = state["enriched_data"]
    messages = state.get("messages", [])
    
    system_prompt = """ìˆ˜ì§‘ëœ ì—¬í–‰ì§€ ì •ë³´ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ì„¸ìš”.
    
    í‰ê°€ ê¸°ì¤€: ì •ë³´ì˜ êµ¬ì²´ì„±, ìµœì‹ ì„±, ì™„ì„±ë„
    
    JSONìœ¼ë¡œë§Œ ì‘ë‹µ:
    {
        "quality_score": 0.0-1.0,
        "assessment": "í‰ê°€ ë‚´ìš©"
    }"""
    
    sample = enriched[:3] if len(enriched) > 3 else enriched
    
    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ì •ë³´ë¥¼ í‰ê°€í•˜ì„¸ìš”:\n{json.dumps(sample, ensure_ascii=False, indent=2)}")
    ])
    
    try:
        content = response.content.strip()
        if content.startswith("```json"):
            content = content[7:]
        if content.startswith("```"):
            content = content[3:]
        if content.endswith("```"):
            content = content[:-3]
            
        result = json.loads(content.strip())
        score = float(result.get("quality_score", 0.8))
        
        print(f"ì •ë³´ í’ˆì§ˆ ì ìˆ˜: {score:.2f}")
        
        return AgentState(
            info_quality_score=score,
            messages=[AIMessage(content=f"ì •ë³´ í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ (ì ìˆ˜: {score:.2f})")],
            current_step="validate_information"
        )
    except Exception as e:
        print(f"ì •ë³´ ê²€ì¦ ì˜¤ë¥˜: {e}")
        return AgentState(
            info_quality_score=0.7,
            messages=[AIMessage(content="ì •ë³´ ê²€ì¦ì„ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤.")],
            current_step="validate_information"
        )

def filter_options_node(state: AgentState) -> AgentState:
    """Hard constraintë¡œ í•„í„°ë§í•˜ëŠ” ë…¸ë“œ"""
    print("\n=== ì˜µì…˜ í•„í„°ë§ ì¤‘ ===")
    
    enriched = state["enriched_data"]
    prefs = state["user_preferences"]
    messages = state.get("messages", [])
    
    system_prompt = f"""ì‚¬ìš©ìì˜ í•„ìˆ˜ ì¡°ê±´ì— ë§ì§€ ì•ŠëŠ” ì—¬í–‰ì§€ë¥¼ ì œê±°í•˜ì„¸ìš”.
    
    ì‚¬ìš©ì ì¡°ê±´:
    {json.dumps(prefs, ensure_ascii=False, indent=2)}
    
    í•„í„°ë§ ê¸°ì¤€:
    - ì˜ˆì‚° ì´ˆê³¼ (120% ì´ìƒ)
    - ê³„ì ˆ/ì‹œê¸° ë¶€ì í•©
    - ì•ˆì „ ë¬¸ì œ
    - ê¸°ê°„ ë¶€ì í•©
    
    ì í•©í•œ ì—¬í–‰ì§€ë§Œ JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”."""
    
    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ë‹¤ìŒ ì¤‘ ì í•©í•œ ì—¬í–‰ì§€ë§Œ ì„ íƒí•˜ì„¸ìš”:\n{json.dumps(enriched, ensure_ascii=False, indent=2)}")
    ])
    
    try:
        content = response.content.strip()
        if content.startswith("```json"):
            content = content[7:]
        if content.startswith("```"):
            content = content[3:]
        if content.endswith("```"):
            content = content[:-3]
            
        filtered = json.loads(content.strip())
        print(f"í•„í„°ë§ ê²°ê³¼: {len(filtered)}ê°œ")
        
        return AgentState(
            filtered_options=filtered,
            messages=[AIMessage(content=f"{len(filtered)}ê°œì˜ ì í•©í•œ ì—¬í–‰ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")],
            current_step="filter_options"
        )
    except Exception as e:
        print(f"í•„í„°ë§ ì˜¤ë¥˜: {e}")
        return AgentState(
            filtered_options=enriched,
            messages=[AIMessage(content="í•„í„°ë§ì„ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤.")],
            current_step="filter_options"
        )

def rank_destinations_node(state: AgentState) -> AgentState:
    """ì—¬í–‰ì§€ ìˆœìœ„ ë§¤ê¸°ê¸° ë…¸ë“œ"""
    print("\n=== ì—¬í–‰ì§€ ìˆœìœ„í™” ì¤‘ ===")
    
    filtered = state["filtered_options"]
    prefs = state["user_preferences"]
    messages = state.get("messages", [])
    
    # ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ìš°ì„ ìˆœìœ„ë‚˜ ì„ í˜¸ íŒŒì•…
    conversation_context = "\n".join([
        msg.content for msg in messages[-8:] 
        if isinstance(msg, HumanMessage)
    ])
    
    system_prompt = f"""ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ì í•©í•œ ì—¬í–‰ì§€ ìƒìœ„ 3ê°œë¥¼ ì„ ì •í•˜ì„¸ìš”.
    
    ì‚¬ìš©ì ì„ í˜¸ë„:
    {json.dumps(prefs, ensure_ascii=False, indent=2)}
    
    ì‚¬ìš©ìê°€ ëŒ€í™”ì—ì„œ ì–¸ê¸‰í•œ ë‚´ìš©:
    {conversation_context}
    
    ê° ì—¬í–‰ì§€ì— ëŒ€í•´:
    - match_score (0-100)
    - ranking_reason (ëŒ€í™” ë‚´ìš©ê³¼ ì—°ê²°í•˜ì—¬ ì„¤ëª…)
    
    ìƒìœ„ 3ê°œë¥¼ ranking ìˆœì„œëŒ€ë¡œ JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”."""
    
    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ë‹¤ìŒ ì—¬í–‰ì§€ë¥¼ ìˆœìœ„í™”í•˜ì„¸ìš”:\n{json.dumps(filtered, ensure_ascii=False, indent=2)}")
    ])
    
    try:
        ranked = extract_json(response.content)
        top3 = ranked[:3] if len(ranked) >= 3 else ranked
        print(f"Top {len(top3)} ì„ ì • ì™„ë£Œ")
        
        return AgentState(
            final_recommendations=top3,
            messages=[AIMessage(content="ìµœì¢… ì¶”ì²œì§€ë¥¼ ì„ ì •í–ˆìŠµë‹ˆë‹¤.")],
            current_step="rank_destinations"
        )
    except Exception as e:
        print(f"ìˆœìœ„í™” ì˜¤ë¥˜: {e}")
        return AgentState(
            final_recommendations=filtered[:3],
            messages=[AIMessage(content="ìˆœìœ„í™”ë¥¼ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤.")],
            current_step="rank_destinations"
        )


def final_check_node(state: AgentState) -> AgentState:
    """ìµœì¢… ê²€ì¦ ë…¸ë“œ"""
    print("\n=== ìµœì¢… ê²€ì¦ ì¤‘ ===")
    
    recommendations = state["final_recommendations"]
    prefs = state["user_preferences"]
    messages = state.get("messages", [])
    
    system_prompt = f"""ìµœì¢… ì¶”ì²œì´ ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
    
    ì‚¬ìš©ì ì„ í˜¸ë„:
    {json.dumps(prefs, ensure_ascii=False, indent=2)}
    
    ì¶”ì²œ ê²°ê³¼:
    {json.dumps(recommendations, ensure_ascii=False, indent=2)}
    
    í™•ì¸ ì‚¬í•­:
    - ì¶”ì²œ ì´ìœ ì˜ ë…¼ë¦¬ì„±
    - ì‚¬ìš©ì ë‹ˆì¦ˆ ì¶©ì¡±ë„
    - ì‹¤í˜„ ê°€ëŠ¥ì„±
    - ì •ë³´ì˜ ì™„ì„±ë„
    
    JSONìœ¼ë¡œ ì‘ë‹µ: {{"approved": true/false, "comments": "í‰ê°€"}}"""
    
    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content="ìµœì¢… ê²€ì¦í•´ì£¼ì„¸ìš”.")
    ])
    
    try:
        content = response.content.strip()
        if content.startswith("```json"):
            content = content[7:]
        if content.startswith("```"):
            content = content[3:]
        if content.endswith("```"):
            content = content[:-3]
            
        result = json.loads(content.strip())
        approved = result.get("approved", True)
        comments = result.get("comments", "")
        
        print(f"ìµœì¢… ê²€ì¦: {'âœ“ í†µê³¼' if approved else 'âœ— ì‹¤íŒ¨'}")
        
        return AgentState(
            messages=[AIMessage(content=f"ìµœì¢… ê²€ì¦: {comments}")],
            current_step="final_check"
        )
    except Exception as e:
        print(f"ìµœì¢… ê²€ì¦ ì˜¤ë¥˜: {e}")
        return AgentState(
            messages=[AIMessage(content="ìµœì¢… ê²€ì¦ì„ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤.")],
            current_step="final_check"
        )

def present_recommendations_node(state: AgentState) -> AgentState:
    """ìµœì¢… ì¶”ì²œ ì œì‹œ ë…¸ë“œ"""
    print("\n=== ì¶”ì²œ ê²°ê³¼ ì œì‹œ ===")
    
    recommendations = state["final_recommendations"]
    prefs = state["user_preferences"]
    messages = state.get("messages", [])
    
    system_prompt = """ì‚¬ìš©ìì—ê²Œ ë§¤ë ¥ì ìœ¼ë¡œ ì—¬í–‰ì§€ë¥¼ ì†Œê°œí•˜ì„¸ìš”.
    
    ê° ì—¬í–‰ì§€ë³„ë¡œ:
    1. ğŸŒŸ ì œëª©ê³¼ í•œ ì¤„ ìš”ì•½
    2. ğŸ’¡ ì¶”ì²œ ì´ìœ  (ëŒ€í™” ë‚´ìš©ê³¼ ì—°ê²°)
    3. ğŸ“… ì˜ˆìƒ ì¼ì •
    4. ğŸ’° ì˜ˆì‚° ê°€ì´ë“œ
    5. âœ¨ í•µì‹¬ íŒ
    
    ì´ì „ ëŒ€í™” íë¦„ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”."""
    
    # ì „ì²´ ëŒ€í™” í¬í•¨í•˜ì—¬ ì‚¬ìš©ìì˜ í†¤ê³¼ ìš”êµ¬ì‚¬í•­ íŒŒì•…
    recent_messages = messages[-10:] if len(messages) > 10 else messages
    chat_messages = [SystemMessage(content=system_prompt)] + recent_messages + [
        HumanMessage(content=f"""
ì‚¬ìš©ì ì„ í˜¸ë„: {json.dumps(prefs, ensure_ascii=False)}

ì¶”ì²œ ì—¬í–‰ì§€: {json.dumps(recommendations, ensure_ascii=False, indent=2)}

ë§¤ë ¥ì ì¸ ì¶”ì²œì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """)
    ]
    
    response = llm.invoke(chat_messages)
    
    final_message = f"""
{'='*60}
ğŸŒ ë‹¹ì‹ ì„ ìœ„í•œ ë§ì¶¤í˜• ì—¬í–‰ì§€ ì¶”ì²œ
{'='*60}

{response.content}

{'='*60}
ğŸ“ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì˜µì…˜ì„ ì›í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”!
{'='*60}
    """
    
    print(final_message)
    
    return AgentState(
        messages=[AIMessage(content=final_message)],
        current_step="present_recommendations"
    )

def increment_retry(state: AgentState) -> AgentState:
    """ì¬ì‹œë„ ì¹´ìš´í„° ì¦ê°€"""
    new_count = state.get("retry_count", 0) + 1
    print(f"ì¬ì‹œë„ ì¹´ìš´í„° ì¦ê°€: {new_count}")
    return AgentState(
        retry_count=new_count,
        current_step="increment_retry"
    )

def increment_enrich_retry(state: AgentState) -> AgentState:
    """ì •ë³´ ë³´ê°• ì¬ì‹œë„ ì¹´ìš´í„° ì¦ê°€"""
    new_count = state.get("enrich_retry_count", 0) + 1
    print(f"ì •ë³´ ë³´ê°• ì¬ì‹œë„ ì¹´ìš´í„° ì¦ê°€: {new_count}")
    return AgentState(
        enrich_retry_count=new_count,
        current_step="increment_enrich_retry"
    )